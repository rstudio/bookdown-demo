# Model-data fit analyses {#MD_fit}

## R-Lab: Model-data fit analysis
For the previous lab, we used the R package "TAM" [(Robitzsch et al., 2018)](https://cran.r-project.org/web/packages/eRm/eRm.pdf) to run the Dichotomous Rasch analyses. In this lab, we will focus on another R Rasch package, which is the "eRm" package [(Mair & Hatzinger, 2007)](https://cran.r-project.org/web/packages/TAM/TAM.pdf). Please note that when we used "TAM" package with the MML estimation method, the item-person map looks a bit different compared with that produced by the "eRm" package which applies CML estimation.

### Get Data Prepared
We are going to practice evaluating model-data fit with the transitive reasoning data from the previous lab.

```{r message=FALSE}
# Load the R-packages that you're going to use
library("eRm") # For running the Dichotomous Rasch Model
library("readr") # To import the data
```

```{r message=FALSE}
# Import the data
transreas <- read.csv("transreas.csv") 
summary(transreas)
```

### Trim the data
Similar to the "TAM" package, we only need the responses to run the Dichotomous Rasch model with the "eRm" package. To get started, we need to remove the first two columns from the dataframe.

```{r}
# Trim the data
Di_Rasch_data <- transreas[ ,c(-1,-2)]
head(Di_Rasch_data,10) # Take a look
```
### Running Dichotomous Rasch Model with "eRm" package
We will use the "RM" function to run the Rasch dichotomous model. This function computes the parameter estimates of a Rasch model for binary item responses by using CML estimation.

```{r}
# Running the Dichotomous Rasch Model
Di_Rasch_model <- RM(Di_Rasch_data)
# Check the Overall model summary
summary(Di_Rasch_model)
# To achieve the Item difficulty
item.diff <- Di_Rasch_model$betapar * -1
item.diff
# Use the summary() function to get a quick numeric summary of the item parameters
summary(item.diff)
# We can see that the average item difficulty value is 0.00 logits, and item difficulties range from -2.18 to 1.04 logits.
# We can also look at the standard errors for the item locations:
item.se <- Di_Rasch_model$se.beta
item.se
summary(item.se)
```
Note the Estimate in this output indicates the easiness of the Item. This is exactly the item difficulty, but in the opposite direction. The higher the value of this parameter, the easier the item is compared to the other items. You can multiply this value by -1 to get item difficulty.

## Model-data fit Analysis in R

The Model-data fit in the context of Rasch is different from other IRT models. Other IRT approach is focus on finding the _best model_ to fit the data. However, the Rasch approach focuses on diagnosing departures from model expectations. Within the Rasch framework, the model is viewed as an _"ideal type"_. It is a theoretical mathematical description of what measurement looks like. Its fit statistics summarize discrepancies between observations and expectations to help researchers improve their measurement procedures.

### Reliability Indices in Rasch Measurement

> Definition of reliability in the 2014 Test Standards

>  The general notion of reliabilty/precision is defined in terms of consistency over replications of the testing procedure. Reliability/precision is high if  the scores for each person are consistent over replications of the testing procedure and is low if the scores are not consistent over replications. (p. 35, emphasis added)

From a Rasch perspective, the focus for reliability analyses is on **ordering** and **separation** on the logit scale. There are two major indices calculated for items and persons: one is the reliability of separation, and the other is the Chi-Square separation statistic.

The Rasch reliability of separation is calculated for each facet in the model (e.g., items & persons), and it is an estimate of **how well we can differentiate** individual items, persons, or other elements on the latent variable. It is conceptually related to Cronbach's alpha coefficient. The interpretation is the same when data fit the model. The statistic ranges from 0 to 1. 

#### Reliability of Person Separation
Calculated using a ratio of true (adjusted) variance to observed variance for persons:
$$Rel_{p}=\left(SA_{P}^{2}\right) /\left(SD_{P}^{2}\right)$$
Where:
	  *SA^2^~P~* : Adjusted person variability;
    Calculated by subtracting error variance for persons from total person variance: $$ SA_{P}^{2} = SD_{P}^{2} - SE_{P}^{2}$$
	  *SD^2^~P~* : Total person variance

#### Calculate the Reliability of Person Separation
The "eRm" package provides function "SepRel" to calculate the person separation reliability. This function calculates the proportion of person variance that is not due to error. The concept of person separation reliability is very similar to reliability indices such as Cronbach's α.

```{r}
# Get the person parameter first by using the "person.parameter" function
person_pa <- person.parameter(Di_Rasch_model)
# Calculate the Reliability of Person Separation
summary(SepRel(person_pa))
```

#### Reliability of Item Separation
Calculated using a ratio of true (adjusted) variance to observed variance for Items:
$$Rel_{I}=\left(SA_{I}^{2}\right) /\left(SD_{I}^{2}\right)$$
Where:
	  *SA^2^~I~* : Adjusted item variability;
    Calculated by subtracting error variance for Item from total Item          variance: $$ SA_{I}^{2} = SD_{I}^{2} - SE_{I}^{2}$$
	  *SD^2^~I~* : Total Item variance
	  
### Item Information Curve (*IIC*)
Many IRT analyses also look at item information as evidence for precision. This is a statistical summary of the variance of item responses about a certain range on the latent variable. We can use this information to find out **if** and **where** items are providing information about person locations.
IIC is not a major component of Rasch analyses, because the information is the same for all items in the dichotomous model (same shape). This is because the item slope parameter is fixed to 1 for all items, so all of the items discriminate among students the same way.

```{r}
# Use "plotINFO" function for visualizing the item information
plotINFO(Di_Rasch_model)
```

### Summaries of residuals: Infit & Outfit

The most popular Rasch fit statistics for practical purposes are based on summed squared residuals. There are two major categories of residual summary statistics: Unweighted (Outfit) and Weighted (Infit) mean square error (MSE) statistics. Unstandardized (χ2) & standardized versions (Z) are available in most Rasch software programs. In this analysis, we will use the Unstandardized (χ2) version.

#### Outfit Mean Square Error (MSE)

Outfit is the “Unweighted fit” statistic. For items, it is the sum of squared residuals for an item divided by the number of persons who responded to the item. For persons, it is sum of squared residuals for a person divided by the number of items encountered by the person.

The outfit is sensitive to extreme departures from model expectations. Examples: A high-achieving student provides an incorrect response to a very easy item; A low-achieving student provides a correct response to a very difficult item.

#### Infit Mean Square Error (MSE)

Infit is "Information-weighted fit", where "information" means *variance*, such as larger variance for well-targeted observations, or smaller variance for extreme observations.

For items, it is the sum of squared standardized *item residuals*, weighted by variance, divided by the number of persons who responded to the item. For persons, it is the sum of squared standardized *person residuals*, weighted by variance, divided by the number of items the person encountered.

Infit is sensitive to less-extreme unexpected responses compared to outfit. Examples of less-extreme unexpected responses include: A person provides an incorrect response to an item that is just below their achievement level, or a person provides a correct response to an item that is just above their achievement level.

#### Expected values for MSE Fit Statistics

Note that there is much disagreement among measurement scholars about how to classify an infit our outfit statistic as "fitting" or "misfitting." We will talk about this in class. 

However, you should be aware of commonly accepted rule-of-thumb values among Rasch researchers:

- Expected value is about 1.00 when data fit the model

- Less than 1.00: Responses are too predictable; they resemble a Guttman-like (deterministic) pattern (“muted”)

- More than 1.00: Responses are too haphazard (“noisy”); there is too much variation to suggest that the estimate is a good representation of the response pattern

- Some variation is expected, but noisy responses are usually more cause for concern than muted responses

Frequently Used Critical Values for Mean Square Fit Statistics [(Bond & Fox, p. 273, Table 12.7)](https://psycnet.apa.org/record/2007-07586-000)

| *Type of Instrument* | *"Acceptable Range"* | 
| :---:        |    :----:   | 
| Multiple-choice test (high-stakes) | 0.80 – 1.20 | 
| Multiple-choice test (not high-stakes)| 0.70 – 1.30 | 
| Rating scale | 0.60 – 1.40 | 
| Clinical observation | 0.50 – 1.70 | 
| Judgment (when agreement is encouraged) | 0.40 – 1.20| 

*Note: These critical values are a very contentious topic in Rasch measurement!!!

#### Calculate Infit & Outfit for the transitive reasoning data
```{r}
# Calculate the Item fit statistics using "itemfit" function on your person parameter object
Di_itemfit <- itemfit(person_pa)
Di_itemfit
```
This table will give us information about the infit and outfit statistics for each item. Please review our lecture materials for details about the interpretation of these values, noting that we generally expect these statistics to be around 1.00.

```{r}
# Calculate the Person fit statistics
person_fit <- personfit(person_pa)
# Since person_fit is a long list, we can summarize it to get the aggregated value.
summary(person_fit$p.infitMSQ)
summary(person_fit$p.outfitMSQ)
```

- We can see that there is some variability in person fit, with infit MSE statistics ranging from 0.41 to 2.25, and outfit MSE statistics ranging from 0.17 to 7.30:

- From this fit analysis, we can see that the mean of the infit MSE and outfit MSE statistics are close to 1.0. 


```{r}
# Also, you can use the "personMisfit" function to find the person who misfit 
misfit_person <- PersonMisfit(person_pa) 
# This function counts the number of persons who do not fit the Rasch model. More specifically, it returns the proportion and frequency of persons - or more generally cases - who exceed a Chi-square based Z-value of 1.96 (suggesting a statistically significant deviation from the predicted response pattern).
misfit_person
# About 1.6043% persons are misfitting
misfit_person$count.misfit.Z
# The detailed number for misfitting is 6
misfit_person$total.persons
# This is the number of persons for whom a fit value was estimated
```

### Item/Person Map
The "eRm" package provides plotting function to show the location of item/person on both logit scale and their t stastistics.

```{r}
plotPWmap(Di_Rasch_model,imap=TRUE) # You can plot the Item Map
plotPWmap(Di_Rasch_model,pmap=TRUE) # You can even put the person and item inside one map
```
Also, we can construct a plot that shows item and person locations in the same graphical display (a Person-Item Map). 

```{r}
#To do this, use the following code:
plotPImap(Di_Rasch_model, sorted = TRUE)
```
In this plot, we should consider the degree to which there is evidence of overlap between item and person locations (targeting).

We can also examine the individual items’ ordering on the logit scale with reference to our theory about the expected ordering.


### Item Characteristic Curves (ICC)
The *IRFs/ICCs* that we have been looking at are based on model-expected response probabilities.

```{r}
plotICC(Di_Rasch_model,mplot=TRUE,ask = FALSE)
```
Note that the R package did not plot the observed probability.

### Plots of standardized residuals
Let’s use some graphical displays to examine item fit in more detail. Please review our lecture materials for details about these displays. These plots show the standardized residual for the difference between the observed and expected response for each person on the item of interest.
```{r}
# Collect the residual values from the Itemfit results
stresid <- Di_itemfit$st.res
# before constructing the plots, find the max & min residuals:
max.resid <- ceiling(max(stresid))
min.resid <- ceiling(min(stresid))
# The code below will produce standardized residual plots for each of the items in our example dataset in the “Plots” window on the bottom right of your R Studio window:
for(item.number in 1:ncol(stresid)){
  
  plot(stresid[, item.number], ylim = c(min.resid, max.resid),
       main = paste("Standardized Residuals for Item ", item.number, sep = ""),
       ylab = "Standardized Residual", xlab = "Person Index")
  abline(h = 0, col = "blue")
  abline(h=2, lty = 2, col = "red")
  abline(h=-2, lty = 2, col = "red")
  
  legend("topright", c("Std. Residual", "Observed = Expected", "+/- 2 SD"), pch = c(1, NA, NA), 
         lty = c(NA, 1, 2),
         col = c("black", "blue", "red"), cex = .8)
  
}

```

Then, we are going to plot the item characteristic curves (item response functions; IRFs) with the observed responses overlaid on them. These are sometimes called empirical IRFs.

```{r}
for(item.number in 1:ncol(stresid)){
  plotICC(Di_Rasch_model, item.subset = item.number, empICC = list("raw"), empCI = list())
}
```


## Supplmentary Learning Materials
1. [*What do Infit and Outfit, Mean-Square and Standardized mean?*](https://www.rasch.org/rmt/rmt162f.htm)

2. [Wright, B.D., & Masters, G.N. (1990). Computation of OUTFIT and INFIT Statistics. *Rasch Measurement Transactions,3(4)* p.84-85.](https://www.rasch.org/rmt/rmt34e.htm)

3. [Estimation methods: JMLE, PROX, WMLE, CMLE](https://www.winsteps.com/winman/estimation.htm)
